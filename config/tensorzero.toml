# TensorZero Configuration with Environment Variables
# This configuration uses environment variables for sensitive data
# Database is configured via TENSORZERO_CLICKHOUSE_URL environment variable

# Gateway server configuration
[gateway]
bind = "0.0.0.0:3000"

# Model configuration using environment variables
[models]

# RustProxy model for DevV AI
[models.claude-3-5-haiku]
routing = ["devv-rustproxy"]

[models.claude-3-5-haiku.providers.devv-rustproxy]
type = "rust-proxy"
model_name = "claude-3.5-haiku"

# DeepSeek models using your API key
[models.deepseek-chat]
routing = ["deepseek"]

[models.deepseek-chat.providers.deepseek]
type = "deepseek"
model_name = "deepseek-chat"
api_key_location = "env::DEEPSEEK_API_KEY"

[models.deepseek-coder]
routing = ["deepseek"]

[models.deepseek-coder.providers.deepseek]
type = "deepseek"
model_name = "deepseek-coder"
api_key_location = "env::DEEPSEEK_API_KEY"

# OpenRouter models using your API key
[models.openrouter-claude]
routing = ["openrouter"]

[models.openrouter-claude.providers.openrouter]
type = "openrouter"
model_name = "anthropic/claude-3.5-sonnet"
api_key_location = "env::OPENROUTER_API_KEY"

[models.openrouter-gpt4]
routing = ["openrouter"]

[models.openrouter-gpt4.providers.openrouter]
type = "openrouter"
model_name = "openai/gpt-4o"
api_key_location = "env::OPENROUTER_API_KEY"

# Function definitions
[functions]

[functions.basic_chat]
type = "chat"

[functions.basic_chat.variants.claude_variant]
type = "chat_completion"
model = "claude-3-5-haiku"
weight = 1.0

 